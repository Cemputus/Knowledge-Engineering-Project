{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Smart Agriculture Advisor for Crops & Pests\n",
        "## Hybrid Intelligent System: Knowledge Engineering + Deep Learning\n",
        "\n",
        "**Course:** DSC3113 - Knowledge Engineering  \n",
        "**Project:** Group 2 - Smart Agriculture Advisor  \n",
        "**Institution:** Uganda Christian University  \n",
        "**Semester:** Advent 2025\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "1. [Introduction](#introduction)\n",
        "2. [Data Collection & Loading](#data-collection)\n",
        "3. [Exploratory Data Analysis (EDA)](#eda)\n",
        "4. [Knowledge Engineering Setup](#knowledge-engineering)\n",
        "5. [Deep Learning Setup](#deep-learning)\n",
        "6. [Hybrid Integration](#hybrid-integration)\n",
        "7. [Evaluation](#evaluation)\n",
        "8. [Case Studies](#case-studies)\n",
        "9. [Results and Discussion](#results)\n",
        "10. [Conclusion and Recommendations](#conclusion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"introduction\"></a>\n",
        "## 1. Introduction\n",
        "\n",
        "### Problem Statement\n",
        "Farmers worldwide struggle with early identification of crop diseases and pests, leading to significant yield losses. Traditional diagnostic methods rely heavily on expert knowledge, which may not always be accessible to smallholder farmers. This project addresses this challenge by developing a hybrid intelligent system that combines:\n",
        "\n",
        "- **Knowledge Engineering (KE)**: Expert rules and ontologies for symbolic reasoning about diseases, symptoms, and treatments\n",
        "- **Deep Learning (DL)**: Convolutional Neural Networks (CNNs) for image-based disease recognition\n",
        "\n",
        "### Objectives\n",
        "1. Build an agriculture ontology connecting crops, pests, diseases, symptoms, and treatments\n",
        "2. Encode at least 20 expert rules for disease diagnosis and treatment recommendations\n",
        "3. Train CNN models to classify crop diseases from leaf images\n",
        "4. Integrate KE reasoning with DL predictions for hybrid decision-making\n",
        "5. Evaluate the system's accuracy and provide actionable recommendations\n",
        "\n",
        "### Dataset\n",
        "- **Cassava Leaf Disease Classification Dataset**: https://www.kaggle.com/competitions/cassava-disease\n",
        "- **Disease Classes**: \n",
        "  - Cassava Bacterial Blight (CBB)\n",
        "  - Cassava Brown Streak Disease (CBSD)\n",
        "  - Cassava Green Mottle (CGM)\n",
        "  - Cassava Mosaic Disease (CMD)\n",
        "  - Healthy\n",
        "\n",
        "### Relevance\n",
        "This hybrid system bridges the gap between rule-based expert systems and data-driven AI, providing farmers with accessible, accurate disease diagnosis and treatment recommendations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### System Architecture\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│              Smart Agriculture Advisor System                │\n",
        "├─────────────────────────────────────────────────────────────┤\n",
        "│                                                              │\n",
        "│  ┌──────────────┐         ┌──────────────┐                 │\n",
        "│  │   CNN Model  │────────▶│  Disease     │                 │\n",
        "│  │  (Image      │         │  Prediction  │                 │\n",
        "│  │  Classifier) │         │              │                 │\n",
        "│  └──────────────┘         └──────┬───────┘                 │\n",
        "│                                   │                         │\n",
        "│  ┌──────────────┐                │                         │\n",
        "│  │  Knowledge   │                ▼                         │\n",
        "│  │  Base        │         ┌──────────────┐                 │\n",
        "│  │  (Ontology + │────────▶│  Hybrid      │                 │\n",
        "│  │   Rules)     │         │  Reasoning   │                 │\n",
        "│  └──────────────┘         │  Engine      │                 │\n",
        "│                           └──────┬───────┘                 │\n",
        "│                                   │                         │\n",
        "│                                   ▼                         │\n",
        "│                           ┌──────────────┐                 │\n",
        "│                           │  Treatment   │                 │\n",
        "│                           │  & Advice    │                 │\n",
        "│                           │  Output      │                 │\n",
        "│                           └──────────────┘                 │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## 2. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q opendatasets owlready2 rdflib scikit-learn tensorflow keras numpy pandas matplotlib seaborn pillow opencv-python scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.applications import MobileNetV2, InceptionV3, EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Image processing\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Knowledge Engineering\n",
        "try:\n",
        "    from owlready2 import *\n",
        "except:\n",
        "    print(\"Note: owlready2 installation may require additional setup\")\n",
        "import rdflib\n",
        "from rdflib import Graph, Namespace, Literal, URIRef\n",
        "from rdflib.namespace import RDF, RDFS, OWL\n",
        "\n",
        "# Visualization\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"✓ All libraries imported successfully\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"data-collection\"></a>\n",
        "## 3. Data Collection & Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset configuration\n",
        "DATASET_NAME = \"cassava-leaf-disease-classification\"\n",
        "DATASET_PATH = \"./cassava-leaf-disease-classification\"  # Adjust path as needed\n",
        "\n",
        "# Disease class mappings\n",
        "DISEASE_CLASSES = {\n",
        "    0: \"Cassava_Bacterial_Blight\",\n",
        "    1: \"Cassava_Brown_Streak_Disease\", \n",
        "    2: \"Cassava_Green_Mottle\",\n",
        "    3: \"Cassava_Mosaic_Disease\",\n",
        "    4: \"Healthy\"\n",
        "}\n",
        "\n",
        "CLASS_NAMES_SHORT = {\n",
        "    0: \"CBB\",\n",
        "    1: \"CBSD\",\n",
        "    2: \"CGM\", \n",
        "    3: \"CMD\",\n",
        "    4: \"Healthy\"\n",
        "}\n",
        "\n",
        "print(\"Disease Classes:\")\n",
        "for idx, name in DISEASE_CLASSES.items():\n",
        "    print(f\"  {idx}: {name} ({CLASS_NAMES_SHORT[idx]})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset (uncomment if needed)\n",
        "# import opendatasets as od\n",
        "# od.download(f\"https://www.kaggle.com/competitions/{DATASET_NAME}\")\n",
        "\n",
        "# Alternative: Load from local path\n",
        "# Adjust this path to your dataset location\n",
        "BASE_DATA_PATH = Path(\"./cassava-leaf-disease-classification/data\")\n",
        "\n",
        "# If dataset is in a different location, update here\n",
        "# BASE_DATA_PATH = Path(\"/content/drive/MyDrive/cassava-leaf-disease-classification/data\")\n",
        "# BASE_DATA_PATH = Path(\"cassava-disease/data\")\n",
        "\n",
        "print(f\"Looking for dataset at: {BASE_DATA_PATH.absolute()}\")\n",
        "\n",
        "if BASE_DATA_PATH.exists():\n",
        "    print(\"✓ Dataset folder found\")\n",
        "else:\n",
        "    print(\"⚠ Dataset folder not found. Please update BASE_DATA_PATH\")\n",
        "    print(\"   Expected structure:\")\n",
        "    print(\"   cassava-leaf-disease-classification/\")\n",
        "    print(\"     └── data/\")\n",
        "    print(\"         ├── Cassava___bacterial_blight/\")\n",
        "    print(\"         ├── Cassava___brown_streak_disease/\")\n",
        "    print(\"         ├── Cassava___green_mottle/\")\n",
        "    print(\"         ├── Cassava___mosaic_disease/\")\n",
        "    print(\"         └── Cassava___healthy/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"eda\"></a>\n",
        "## 4. Exploratory Data Analysis (EDA)\n",
        "\n",
        "### 4.1 Dataset Structure Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dataset_structure(base_path):\n",
        "    \"\"\"Analyze the structure and statistics of the dataset\"\"\"\n",
        "    \n",
        "    if not Path(base_path).exists():\n",
        "        print(f\"⚠ Path {base_path} does not exist\")\n",
        "        return None, None\n",
        "    \n",
        "    class_stats = {}\n",
        "    total_images = 0\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n",
        "    \n",
        "    # Expected folder names mapping\n",
        "    folder_mapping = {\n",
        "        'Cassava___bacterial_blight': 0,\n",
        "        'Cassava___brown_streak_disease': 1,\n",
        "        'Cassava___green_mottle': 2,\n",
        "        'Cassava___mosaic_disease': 3,\n",
        "        'Cassava___healthy': 4\n",
        "    }\n",
        "    \n",
        "    for folder_name in Path(base_path).iterdir():\n",
        "        if folder_name.is_dir():\n",
        "            # Count images in this folder\n",
        "            image_count = 0\n",
        "            image_sizes = []\n",
        "            \n",
        "            for ext in image_extensions:\n",
        "                images = list(folder_name.glob(f\"*{ext}\"))\n",
        "                image_count += len(images)\n",
        "                \n",
        "                # Sample image sizes (first 10)\n",
        "                for img_path in images[:10]:\n",
        "                    try:\n",
        "                        with Image.open(img_path) as img:\n",
        "                            image_sizes.append(img.size)\n",
        "                    except:\n",
        "                        pass\n",
        "            \n",
        "            # Map folder to class index\n",
        "            class_idx = folder_mapping.get(folder_name.name, -1)\n",
        "            \n",
        "            class_stats[folder_name.name] = {\n",
        "                'count': image_count,\n",
        "                'class_idx': class_idx,\n",
        "                'sample_sizes': image_sizes[:5] if image_sizes else []\n",
        "            }\n",
        "            \n",
        "            total_images += image_count\n",
        "    \n",
        "    return class_stats, total_images\n",
        "\n",
        "# Analyze dataset\n",
        "class_stats, total_images = analyze_dataset_structure(BASE_DATA_PATH)\n",
        "\n",
        "if class_stats:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DATASET STRUCTURE ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nTotal Images: {total_images:,}\\n\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    for folder_name, stats in sorted(class_stats.items(), key=lambda x: x[1]['class_idx']):\n",
        "        class_idx = stats['class_idx']\n",
        "        count = stats['count']\n",
        "        percentage = (count / total_images * 100) if total_images > 0 else 0\n",
        "        \n",
        "        print(f\"Class {class_idx}: {folder_name}\")\n",
        "        print(f\"  Images: {count:,} ({percentage:.2f}%)\")\n",
        "        if stats['sample_sizes']:\n",
        "            print(f\"  Sample sizes: {stats['sample_sizes'][0] if stats['sample_sizes'] else 'N/A'}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"⚠ Could not analyze dataset. Please check the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 4.2 Visual Distribution Analysis\n",
        "\n",
        "if class_stats:\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Extract data for plotting\n",
        "    class_labels = []\n",
        "    counts = []\n",
        "    class_indices = []\n",
        "    \n",
        "    for folder_name, stats in sorted(class_stats.items(), key=lambda x: x[1]['class_idx']):\n",
        "        class_labels.append(CLASS_NAMES_SHORT[stats['class_idx']])\n",
        "        counts.append(stats['count'])\n",
        "        class_indices.append(stats['class_idx'])\n",
        "    \n",
        "    # Bar plot\n",
        "    colors = sns.color_palette(\"husl\", len(class_labels))\n",
        "    bars = axes[0].bar(class_labels, counts, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    axes[0].set_title('Class Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Disease Class', fontsize=12)\n",
        "    axes[0].set_ylabel('Number of Images', fontsize=12)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, counts):\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{count:,}',\n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # Pie chart\n",
        "    wedges, texts, autotexts = axes[1].pie(counts, labels=class_labels, autopct='%1.1f%%',\n",
        "                                           colors=colors, startangle=90, textprops={'fontsize': 11})\n",
        "    axes[1].set_title('Class Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Make percentage text bold\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print statistics\n",
        "    print(\"\\nClass Distribution Statistics:\")\n",
        "    print(\"-\" * 60)\n",
        "    for label, count, idx in zip(class_labels, counts, class_indices):\n",
        "        pct = (count / total_images * 100)\n",
        "        print(f\"{label:8s} (Class {idx}): {count:5,} images ({pct:5.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Sample Image Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_sample_images(base_path, class_stats, num_samples=5):\n",
        "    \"\"\"Visualize sample images from each class\"\"\"\n",
        "    \n",
        "    if not class_stats:\n",
        "        print(\"⚠ No class statistics available\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(len(class_stats), num_samples, figsize=(20, 4*len(class_stats)))\n",
        "    \n",
        "    if len(class_stats) == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    folder_mapping = {\n",
        "        'Cassava___bacterial_blight': 0,\n",
        "        'Cassava___brown_streak_disease': 1,\n",
        "        'Cassava___green_mottle': 2,\n",
        "        'Cassava___mosaic_disease': 3,\n",
        "        'Cassava___healthy': 4\n",
        "    }\n",
        "    \n",
        "    row = 0\n",
        "    for folder_name, stats in sorted(class_stats.items(), key=lambda x: x[1]['class_idx']):\n",
        "        folder_path = Path(base_path) / folder_name\n",
        "        class_idx = stats['class_idx']\n",
        "        class_name = CLASS_NAMES_SHORT[class_idx]\n",
        "        \n",
        "        # Get sample images\n",
        "        image_files = []\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
        "            image_files.extend(list(folder_path.glob(f\"*{ext}\")))\n",
        "        \n",
        "        # Randomly sample\n",
        "        if len(image_files) > num_samples:\n",
        "            image_files = np.random.choice(image_files, num_samples, replace=False)\n",
        "        else:\n",
        "            image_files = image_files[:num_samples]\n",
        "        \n",
        "        for col, img_path in enumerate(image_files[:num_samples]):\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                axes[row, col].imshow(img)\n",
        "                axes[row, col].set_title(f'{class_name}\\n{img_path.name[:20]}...', \n",
        "                                       fontsize=10, fontweight='bold')\n",
        "                axes[row, col].axis('off')\n",
        "            except Exception as e:\n",
        "                axes[row, col].text(0.5, 0.5, f'Error loading\\n{img_path.name}', \n",
        "                                  ha='center', va='center')\n",
        "                axes[row, col].axis('off')\n",
        "        \n",
        "        row += 1\n",
        "    \n",
        "    plt.suptitle('Sample Images from Each Disease Class', fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize samples\n",
        "if class_stats:\n",
        "    visualize_sample_images(BASE_DATA_PATH, class_stats, num_samples=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_image_statistics(base_path, class_stats, sample_per_class=50):\n",
        "    \"\"\"Analyze image statistics including dimensions, color channels, etc.\"\"\"\n",
        "    \n",
        "    if not class_stats:\n",
        "        return None\n",
        "    \n",
        "    all_stats = {\n",
        "        'widths': [],\n",
        "        'heights': [],\n",
        "        'aspect_ratios': [],\n",
        "        'channels': [],\n",
        "        'file_sizes': [],\n",
        "        'classes': []\n",
        "    }\n",
        "    \n",
        "    folder_mapping = {\n",
        "        'Cassava___bacterial_blight': 0,\n",
        "        'Cassava___brown_streak_disease': 1,\n",
        "        'Cassava___green_mottle': 2,\n",
        "        'Cassava___mosaic_disease': 3,\n",
        "        'Cassava___healthy': 4\n",
        "    }\n",
        "    \n",
        "    for folder_name, stats in class_stats.items():\n",
        "        folder_path = Path(base_path) / folder_name\n",
        "        class_idx = stats['class_idx']\n",
        "        \n",
        "        # Get images\n",
        "        image_files = []\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
        "            image_files.extend(list(folder_path.glob(f\"*{ext}\")))\n",
        "        \n",
        "        # Sample images\n",
        "        if len(image_files) > sample_per_class:\n",
        "            image_files = np.random.choice(image_files, sample_per_class, replace=False)\n",
        "        \n",
        "        for img_path in image_files:\n",
        "            try:\n",
        "                # Get file size\n",
        "                file_size = img_path.stat().st_size / (1024 * 1024)  # MB\n",
        "                \n",
        "                # Open and analyze image\n",
        "                with Image.open(img_path) as img:\n",
        "                    width, height = img.size\n",
        "                    channels = len(img.getbands()) if hasattr(img, 'getbands') else 3\n",
        "                    aspect_ratio = width / height\n",
        "                    \n",
        "                    all_stats['widths'].append(width)\n",
        "                    all_stats['heights'].append(height)\n",
        "                    all_stats['aspect_ratios'].append(aspect_ratio)\n",
        "                    all_stats['channels'].append(channels)\n",
        "                    all_stats['file_sizes'].append(file_size)\n",
        "                    all_stats['classes'].append(CLASS_NAMES_SHORT[class_idx])\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    return pd.DataFrame(all_stats)\n",
        "\n",
        "# Analyze image statistics\n",
        "if class_stats:\n",
        "    img_stats_df = analyze_image_statistics(BASE_DATA_PATH, class_stats, sample_per_class=100)\n",
        "    \n",
        "    if img_stats_df is not None and len(img_stats_df) > 0:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"IMAGE STATISTICS ANALYSIS\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"\\nTotal Images Analyzed: {len(img_stats_df):,}\\n\")\n",
        "        print(\"-\" * 60)\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(img_stats_df[['widths', 'heights', 'aspect_ratios', 'file_sizes']].describe())\n",
        "        \n",
        "        # Visualize statistics\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        \n",
        "        # Width distribution\n",
        "        axes[0, 0].hist(img_stats_df['widths'], bins=50, color='skyblue', edgecolor='black')\n",
        "        axes[0, 0].set_title('Image Width Distribution', fontweight='bold')\n",
        "        axes[0, 0].set_xlabel('Width (pixels)')\n",
        "        axes[0, 0].set_ylabel('Frequency')\n",
        "        axes[0, 0].axvline(img_stats_df['widths'].mean(), color='red', linestyle='--', \n",
        "                          label=f'Mean: {img_stats_df[\"widths\"].mean():.0f}')\n",
        "        axes[0, 0].legend()\n",
        "        \n",
        "        # Height distribution\n",
        "        axes[0, 1].hist(img_stats_df['heights'], bins=50, color='lightcoral', edgecolor='black')\n",
        "        axes[0, 1].set_title('Image Height Distribution', fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Height (pixels)')\n",
        "        axes[0, 1].set_ylabel('Frequency')\n",
        "        axes[0, 1].axvline(img_stats_df['heights'].mean(), color='red', linestyle='--',\n",
        "                          label=f'Mean: {img_stats_df[\"heights\"].mean():.0f}')\n",
        "        axes[0, 1].legend()\n",
        "        \n",
        "        # Aspect ratio distribution\n",
        "        axes[1, 0].hist(img_stats_df['aspect_ratios'], bins=50, color='lightgreen', edgecolor='black')\n",
        "        axes[1, 0].set_title('Aspect Ratio Distribution', fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Aspect Ratio (Width/Height)')\n",
        "        axes[1, 0].set_ylabel('Frequency')\n",
        "        axes[1, 0].axvline(img_stats_df['aspect_ratios'].mean(), color='red', linestyle='--',\n",
        "                          label=f'Mean: {img_stats_df[\"aspect_ratios\"].mean():.2f}')\n",
        "        axes[1, 0].legend()\n",
        "        \n",
        "        # File size distribution\n",
        "        axes[1, 1].hist(img_stats_df['file_sizes'], bins=50, color='plum', edgecolor='black')\n",
        "        axes[1, 1].set_title('File Size Distribution', fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('File Size (MB)')\n",
        "        axes[1, 1].set_ylabel('Frequency')\n",
        "        axes[1, 1].axvline(img_stats_df['file_sizes'].mean(), color='red', linestyle='--',\n",
        "                          label=f'Mean: {img_stats_df[\"file_sizes\"].mean():.3f} MB')\n",
        "        axes[1, 1].legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"⚠ Could not analyze image statistics\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_color_distribution(base_path, class_stats, samples_per_class=20):\n",
        "    \"\"\"Analyze color distribution across disease classes\"\"\"\n",
        "    \n",
        "    if not class_stats:\n",
        "        return None\n",
        "    \n",
        "    color_stats = {name: {'mean_rgb': [], 'std_rgb': []} for name in CLASS_NAMES_SHORT.values()}\n",
        "    \n",
        "    folder_mapping = {\n",
        "        'Cassava___bacterial_blight': 0,\n",
        "        'Cassava___brown_streak_disease': 1,\n",
        "        'Cassava___green_mottle': 2,\n",
        "        'Cassava___mosaic_disease': 3,\n",
        "        'Cassava___healthy': 4\n",
        "    }\n",
        "    \n",
        "    for folder_name, stats in class_stats.items():\n",
        "        folder_path = Path(base_path) / folder_name\n",
        "        class_idx = stats['class_idx']\n",
        "        class_name = CLASS_NAMES_SHORT[class_idx]\n",
        "        \n",
        "        image_files = []\n",
        "        for ext in ['.jpg', '.jpeg', '.png']:\n",
        "            image_files.extend(list(folder_path.glob(f\"*{ext}\")))\n",
        "        \n",
        "        if len(image_files) > samples_per_class:\n",
        "            image_files = np.random.choice(image_files, samples_per_class, replace=False)\n",
        "        \n",
        "        for img_path in image_files:\n",
        "            try:\n",
        "                img = np.array(Image.open(img_path))\n",
        "                if len(img.shape) == 3:\n",
        "                    mean_rgb = img.mean(axis=(0, 1))\n",
        "                    std_rgb = img.std(axis=(0, 1))\n",
        "                    color_stats[class_name]['mean_rgb'].append(mean_rgb)\n",
        "                    color_stats[class_name]['std_rgb'].append(std_rgb)\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Mean RGB values by class\n",
        "    mean_data = []\n",
        "    class_names_list = []\n",
        "    for class_name, stats in color_stats.items():\n",
        "        if stats['mean_rgb']:\n",
        "            mean_rgb = np.mean(stats['mean_rgb'], axis=0)\n",
        "            mean_data.append(mean_rgb)\n",
        "            class_names_list.append(class_name)\n",
        "    \n",
        "    if mean_data:\n",
        "        mean_data = np.array(mean_data)\n",
        "        x = np.arange(len(class_names_list))\n",
        "        width = 0.25\n",
        "        \n",
        "        axes[0].bar(x - width, mean_data[:, 0], width, label='Red', color='red', alpha=0.7)\n",
        "        axes[0].bar(x, mean_data[:, 1], width, label='Green', color='green', alpha=0.7)\n",
        "        axes[0].bar(x + width, mean_data[:, 2], width, label='Blue', color='blue', alpha=0.7)\n",
        "        \n",
        "        axes[0].set_xlabel('Disease Class', fontweight='bold')\n",
        "        axes[0].set_ylabel('Mean Pixel Intensity', fontweight='bold')\n",
        "        axes[0].set_title('Average RGB Values by Disease Class', fontweight='bold', fontsize=12)\n",
        "        axes[0].set_xticks(x)\n",
        "        axes[0].set_xticklabels(class_names_list)\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(axis='y', alpha=0.3)\n",
        "        \n",
        "        # Color swatches\n",
        "        for idx, (class_name, rgb_mean) in enumerate(zip(class_names_list, mean_data)):\n",
        "            axes[1].add_patch(plt.Rectangle((0, idx), 1, 0.8, \n",
        "                                           facecolor=rgb_mean/255.0, edgecolor='black', linewidth=2))\n",
        "            axes[1].text(1.1, idx + 0.4, class_name, va='center', fontweight='bold', fontsize=11)\n",
        "        \n",
        "        axes[1].set_xlim(-0.1, 3)\n",
        "        axes[1].set_ylim(-0.5, len(class_names_list))\n",
        "        axes[1].set_title('Average Color by Disease Class', fontweight='bold', fontsize=12)\n",
        "        axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Analyze color distribution\n",
        "if class_stats:\n",
        "    analyze_color_distribution(BASE_DATA_PATH, class_stats, samples_per_class=30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_data_quality(base_path, class_stats):\n",
        "    \"\"\"Check for corrupted images, missing files, etc.\"\"\"\n",
        "    \n",
        "    if not class_stats:\n",
        "        return None\n",
        "    \n",
        "    quality_report = {\n",
        "        'total_checked': 0,\n",
        "        'corrupted': 0,\n",
        "        'valid': 0,\n",
        "        'missing_files': 0,\n",
        "        'corruption_by_class': {}\n",
        "    }\n",
        "    \n",
        "    folder_mapping = {\n",
        "        'Cassava___bacterial_blight': 0,\n",
        "        'Cassava___brown_streak_disease': 1,\n",
        "        'Cassava___green_mottle': 2,\n",
        "        'Cassava___mosaic_disease': 3,\n",
        "        'Cassava___healthy': 4\n",
        "    }\n",
        "    \n",
        "    for folder_name, stats in class_stats.items():\n",
        "        folder_path = Path(base_path) / folder_name\n",
        "        class_idx = stats['class_idx']\n",
        "        class_name = CLASS_NAMES_SHORT[class_idx]\n",
        "        \n",
        "        corrupted_count = 0\n",
        "        valid_count = 0\n",
        "        \n",
        "        image_files = []\n",
        "        for ext in ['.jpg', '.jpeg', '.png']:\n",
        "            image_files.extend(list(folder_path.glob(f\"*{ext}\")))\n",
        "        \n",
        "        for img_path in image_files:\n",
        "            quality_report['total_checked'] += 1\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                img.verify()  # Verify image integrity\n",
        "                img.close()\n",
        "                valid_count += 1\n",
        "                quality_report['valid'] += 1\n",
        "            except Exception as e:\n",
        "                corrupted_count += 1\n",
        "                quality_report['corrupted'] += 1\n",
        "        \n",
        "        quality_report['corruption_by_class'][class_name] = {\n",
        "            'total': len(image_files),\n",
        "            'valid': valid_count,\n",
        "            'corrupted': corrupted_count,\n",
        "            'corruption_rate': (corrupted_count / len(image_files) * 100) if len(image_files) > 0 else 0\n",
        "        }\n",
        "    \n",
        "    return quality_report\n",
        "\n",
        "# Check data quality\n",
        "if class_stats:\n",
        "    quality_report = check_data_quality(BASE_DATA_PATH, class_stats)\n",
        "    \n",
        "    if quality_report:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"DATA QUALITY ASSESSMENT\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"\\nTotal Images Checked: {quality_report['total_checked']:,}\")\n",
        "        print(f\"Valid Images: {quality_report['valid']:,} ({quality_report['valid']/quality_report['total_checked']*100:.2f}%)\")\n",
        "        print(f\"Corrupted Images: {quality_report['corrupted']:,} ({quality_report['corrupted']/quality_report['total_checked']*100:.2f}%)\")\n",
        "        \n",
        "        print(\"\\n\" + \"-\" * 60)\n",
        "        print(\"Corruption Rate by Class:\")\n",
        "        print(\"-\" * 60)\n",
        "        for class_name, stats in quality_report['corruption_by_class'].items():\n",
        "            print(f\"{class_name:8s}: {stats['valid']:5,} valid / {stats['total']:5,} total \"\n",
        "                  f\"({stats['corruption_rate']:.2f}% corrupted)\")\n",
        "        \n",
        "        # Visualize quality\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        classes = list(quality_report['corruption_by_class'].keys())\n",
        "        valid_counts = [quality_report['corruption_by_class'][c]['valid'] for c in classes]\n",
        "        corrupted_counts = [quality_report['corruption_by_class'][c]['corrupted'] for c in classes]\n",
        "        \n",
        "        x = np.arange(len(classes))\n",
        "        width = 0.35\n",
        "        \n",
        "        bars1 = ax.bar(x - width/2, valid_counts, width, label='Valid', color='green', alpha=0.7)\n",
        "        bars2 = ax.bar(x + width/2, corrupted_counts, width, label='Corrupted', color='red', alpha=0.7)\n",
        "        \n",
        "        ax.set_xlabel('Disease Class', fontweight='bold')\n",
        "        ax.set_ylabel('Number of Images', fontweight='bold')\n",
        "        ax.set_title('Data Quality by Disease Class', fontweight='bold', fontsize=12)\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(classes)\n",
        "        ax.legend()\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.7 Class Imbalance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if class_stats:\n",
        "    # Calculate class imbalance metrics\n",
        "    counts = [stats['count'] for stats in sorted(class_stats.values(), key=lambda x: x['class_idx'])]\n",
        "    labels = [CLASS_NAMES_SHORT[idx] for idx in range(len(counts))]\n",
        "    \n",
        "    # Calculate imbalance ratio\n",
        "    max_count = max(counts)\n",
        "    min_count = min(counts)\n",
        "    imbalance_ratio = max_count / min_count\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"CLASS IMBALANCE ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nImbalance Ratio (Max/Min): {imbalance_ratio:.2f}\")\n",
        "    print(f\"Most Frequent Class: {labels[counts.index(max_count)]} ({max_count:,} images)\")\n",
        "    print(f\"Least Frequent Class: {labels[counts.index(min_count)]} ({min_count:,} images)\")\n",
        "    \n",
        "    # Calculate class weights (for balancing during training)\n",
        "    class_weights_array = compute_class_weight('balanced', \n",
        "                                               classes=np.arange(len(counts)),\n",
        "                                               y=np.repeat(np.arange(len(counts)), counts))\n",
        "    class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
        "    \n",
        "    print(\"\\nRecommended Class Weights (for training):\")\n",
        "    print(\"-\" * 60)\n",
        "    for idx, weight in class_weights.items():\n",
        "        print(f\"Class {idx} ({labels[idx]}): {weight:.4f}\")\n",
        "    \n",
        "    # Visualize imbalance\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Count comparison\n",
        "    colors = ['red' if count < max_count * 0.5 else 'orange' if count < max_count * 0.75 else 'green' \n",
        "              for count in counts]\n",
        "    bars = axes[0].bar(labels, counts, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    axes[0].axhline(max_count, color='green', linestyle='--', alpha=0.5, label='Max count')\n",
        "    axes[0].axhline(max_count * 0.5, color='orange', linestyle='--', alpha=0.5, label='50% of max')\n",
        "    axes[0].set_title('Class Distribution (Imbalance Visualization)', fontweight='bold')\n",
        "    axes[0].set_xlabel('Disease Class')\n",
        "    axes[0].set_ylabel('Number of Images')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    for bar, count in zip(bars, counts):\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{count:,}',\n",
        "                    ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "    \n",
        "    # Class weights visualization\n",
        "    weight_values = [class_weights[i] for i in range(len(class_weights))]\n",
        "    axes[1].bar(labels, weight_values, color='steelblue', edgecolor='black', linewidth=1.5)\n",
        "    axes[1].set_title('Recommended Class Weights', fontweight='bold')\n",
        "    axes[1].set_xlabel('Disease Class')\n",
        "    axes[1].set_ylabel('Class Weight')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    for idx, weight in enumerate(weight_values):\n",
        "        axes[1].text(idx, weight, f'{weight:.2f}',\n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"knowledge-engineering\"></a>\n",
        "## 5. Knowledge Engineering Setup\n",
        "\n",
        "### 5.1 Agriculture Ontology Construction\n",
        "\n",
        "We will create an ontology that connects:\n",
        "- **Crops** (Cassava)\n",
        "- **Diseases** (5 cassava diseases)\n",
        "- **Symptoms** (visual and physical symptoms)\n",
        "- **Pests** (related pests)\n",
        "- **Treatments** (recommended treatments and preventive measures)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ontology using RDFLib\n",
        "from rdflib import Graph, Namespace, Literal, URIRef\n",
        "from rdflib.namespace import RDF, RDFS, OWL\n",
        "\n",
        "# Create a new RDF graph\n",
        "kg = Graph()\n",
        "\n",
        "# Define namespaces\n",
        "AGRO = Namespace(\"http://www.agro-ontology.org/#\")\n",
        "EX = Namespace(\"http://example.org/agriculture/\")\n",
        "\n",
        "# Bind namespaces\n",
        "kg.bind(\"agro\", AGRO)\n",
        "kg.bind(\"ex\", EX)\n",
        "kg.bind(\"owl\", OWL)\n",
        "kg.bind(\"rdfs\", RDFS)\n",
        "\n",
        "print(\"✓ Knowledge Graph initialized\")\n",
        "print(f\"  Base namespace: {AGRO}\")\n",
        "print(f\"  Example namespace: {EX}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define classes in the ontology\n",
        "cassava = AGRO.Cassava\n",
        "disease = AGRO.Disease\n",
        "symptom = AGRO.Symptom\n",
        "pest = AGRO.Pest\n",
        "treatment = AGRO.Treatment\n",
        "prevention = AGRO.Prevention\n",
        "\n",
        "# Add class definitions\n",
        "kg.add((cassava, RDF.type, OWL.Class))\n",
        "kg.add((disease, RDF.type, OWL.Class))\n",
        "kg.add((symptom, RDF.type, OWL.Class))\n",
        "kg.add((pest, RDF.type, OWL.Class))\n",
        "kg.add((treatment, RDF.type, OWL.Class))\n",
        "kg.add((prevention, RDF.type, OWL.Class))\n",
        "\n",
        "# Define disease instances\n",
        "diseases = {\n",
        "    'CBB': AGRO.CassavaBacterialBlight,\n",
        "    'CBSD': AGRO.CassavaBrownStreakDisease,\n",
        "    'CGM': AGRO.CassavaGreenMottle,\n",
        "    'CMD': AGRO.CassavaMosaicDisease,\n",
        "    'Healthy': AGRO.HealthyCassava\n",
        "}\n",
        "\n",
        "for name, uri in diseases.items():\n",
        "    kg.add((uri, RDF.type, disease))\n",
        "    kg.add((uri, RDFS.label, Literal(name)))\n",
        "    kg.add((uri, RDFS.comment, Literal(f\"Cassava disease: {name}\")))\n",
        "\n",
        "print(\"✓ Ontology classes and disease instances created\")\n",
        "print(f\"  Total triples: {len(kg)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define symptoms for each disease\n",
        "symptoms_db = {\n",
        "    'CBB': [\n",
        "        'Water-soaked_lesions',\n",
        "        'Angular_leaf_spots',\n",
        "        'Yellowing_leaves',\n",
        "        'Leaf_wilting',\n",
        "        'Black_stems'\n",
        "    ],\n",
        "    'CBSD': [\n",
        "        'Brown_streaks_on_stems',\n",
        "        'Yellowing_between_veins',\n",
        "        'Chlorotic_mottling',\n",
        "        'Root_necrosis',\n",
        "        'Stunted_growth'\n",
        "    ],\n",
        "    'CGM': [\n",
        "        'Green_mottling',\n",
        "        'Irregular_leaf_patterns',\n",
        "        'Reduced_photosynthesis',\n",
        "        'Mild_yellowing',\n",
        "        'Distorted_leaves'\n",
        "    ],\n",
        "    'CMD': [\n",
        "        'Mosaic_patterns',\n",
        "        'Leaf_distortion',\n",
        "        'Reduced_leaf_size',\n",
        "        'Yellow_green_mottling',\n",
        "        'Severe_stunting'\n",
        "    ],\n",
        "    'Healthy': [\n",
        "        'Uniform_green_color',\n",
        "        'No_lesions',\n",
        "        'Normal_growth',\n",
        "        'Healthy_roots',\n",
        "        'Proper_leaf_shape'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Add symptoms to ontology\n",
        "for disease_code, symptom_list in symptoms_db.items():\n",
        "    disease_uri = diseases[disease_code]\n",
        "    for symptom_name in symptom_list:\n",
        "        symptom_uri = AGRO[symptom_name.replace('_', '')]\n",
        "        kg.add((symptom_uri, RDF.type, symptom))\n",
        "        kg.add((symptom_uri, RDFS.label, Literal(symptom_name.replace('_', ' '))))\n",
        "        kg.add((disease_uri, AGRO.hasSymptom, symptom_uri))\n",
        "\n",
        "print(\"✓ Symptoms added to ontology\")\n",
        "print(f\"  Total triples: {len(kg)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define treatments for each disease\n",
        "treatments_db = {\n",
        "    'CBB': [\n",
        "        ('Copper_based_fungicides', 'Apply copper-based fungicides every 7-10 days'),\n",
        "        ('Remove_infected_plants', 'Remove and destroy infected plants immediately'),\n",
        "        ('Crop_rotation', 'Practice crop rotation with non-host crops'),\n",
        "        ('Resistant_varieties', 'Use disease-resistant cassava varieties'),\n",
        "        ('Sanitation', 'Maintain field sanitation and remove plant debris')\n",
        "    ],\n",
        "    'CBSD': [\n",
        "        ('Virus_free_planting_material', 'Use certified virus-free planting material'),\n",
        "        ('Remove_infected_plants', 'Remove and destroy infected plants'),\n",
        "        ('Vector_control', 'Control whitefly vectors using insecticides'),\n",
        "        ('Resistant_varieties', 'Plant CBSD-resistant cassava varieties'),\n",
        "        ('Early_detection', 'Monitor fields regularly for early detection')\n",
        "    ],\n",
        "    'CGM': [\n",
        "        ('Remove_infected_plants', 'Remove and destroy infected plants'),\n",
        "        ('Vector_control', 'Control insect vectors'),\n",
        "        ('Sanitation', 'Maintain clean field conditions'),\n",
        "        ('Resistant_varieties', 'Use resistant cassava varieties'),\n",
        "        ('Proper_spacing', 'Ensure proper plant spacing for air circulation')\n",
        "    ],\n",
        "    'CMD': [\n",
        "        ('Virus_free_planting_material', 'Use certified virus-free cassava cuttings'),\n",
        "        ('Remove_infected_plants', 'Remove and destroy infected plants immediately'),\n",
        "        ('Vector_control', 'Control whitefly populations'),\n",
        "        ('Resistant_varieties', 'Plant CMD-resistant varieties'),\n",
        "        ('Early_harvesting', 'Harvest early if infection is detected')\n",
        "    ],\n",
        "    'Healthy': [\n",
        "        ('Maintain_health', 'Continue good agricultural practices'),\n",
        "        ('Regular_monitoring', 'Monitor for early signs of disease'),\n",
        "        ('Preventive_measures', 'Apply preventive measures'),\n",
        "        ('Proper_nutrition', 'Ensure adequate soil nutrition'),\n",
        "        ('Water_management', 'Maintain proper irrigation')\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Add treatments to ontology\n",
        "for disease_code, treatment_list in treatments_db.items():\n",
        "    disease_uri = diseases[disease_code]\n",
        "    for treatment_name, treatment_desc in treatment_list:\n",
        "        treatment_uri = AGRO[treatment_name.replace('_', '')]\n",
        "        kg.add((treatment_uri, RDF.type, treatment))\n",
        "        kg.add((treatment_uri, RDFS.label, Literal(treatment_name.replace('_', ' '))))\n",
        "        kg.add((treatment_uri, RDFS.comment, Literal(treatment_desc)))\n",
        "        kg.add((disease_uri, AGRO.hasTreatment, treatment_uri))\n",
        "\n",
        "print(\"✓ Treatments added to ontology\")\n",
        "print(f\"  Total triples: {len(kg)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define pests related to cassava diseases\n",
        "pests_db = {\n",
        "    'Whitefly': ['CMD', 'CBSD'],\n",
        "    'Aphids': ['CMD'],\n",
        "    'Mealybugs': ['CMD'],\n",
        "    'Thrips': ['CGM'],\n",
        "    'Mites': ['CGM']\n",
        "}\n",
        "\n",
        "# Add pests to ontology\n",
        "for pest_name, related_diseases in pests_db.items():\n",
        "    pest_uri = AGRO[pest_name.replace(' ', '')]\n",
        "    kg.add((pest_uri, RDF.type, pest))\n",
        "    kg.add((pest_uri, RDFS.label, Literal(pest_name)))\n",
        "    for disease_code in related_diseases:\n",
        "        disease_uri = diseases[disease_code]\n",
        "        kg.add((disease_uri, AGRO.vectorPest, pest_uri))\n",
        "\n",
        "print(\"✓ Pests added to ontology\")\n",
        "print(f\"  Total triples: {len(kg)}\")\n",
        "print(f\"\\nOntology Summary:\")\n",
        "print(f\"  - Diseases: {len(diseases)}\")\n",
        "print(f\"  - Symptoms: {sum(len(s) for s in symptoms_db.values())}\")\n",
        "print(f\"  - Treatments: {sum(len(t) for t in treatments_db.values())}\")\n",
        "print(f\"  - Pests: {len(pests_db)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Expert Rules Encoding (Minimum 20 Rules)\n",
        "\n",
        "We will encode expert rules that capture agricultural knowledge about disease diagnosis and treatment recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Expert Rules Base\n",
        "# Rules are structured as: IF conditions THEN conclusion\n",
        "\n",
        "class ExpertRules:\n",
        "    \"\"\"Expert rule base for cassava disease diagnosis and treatment\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.rules = []\n",
        "        self.initialize_rules()\n",
        "    \n",
        "    def initialize_rules(self):\n",
        "        \"\"\"Initialize at least 20 expert rules\"\"\"\n",
        "        \n",
        "        # Rule 1-5: CBB (Cassava Bacterial Blight) Rules\n",
        "        self.rules.append({\n",
        "            'id': 1,\n",
        "            'name': 'CBB_Rule_1',\n",
        "            'conditions': ['Water_soaked_lesions', 'Angular_leaf_spots'],\n",
        "            'conclusion': 'CBB',\n",
        "            'confidence': 0.85,\n",
        "            'description': 'If water-soaked lesions AND angular leaf spots → Cassava Bacterial Blight'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 2,\n",
        "            'name': 'CBB_Rule_2',\n",
        "            'conditions': ['Yellowing_leaves', 'Black_stems'],\n",
        "            'conclusion': 'CBB',\n",
        "            'confidence': 0.80,\n",
        "            'description': 'If yellowing leaves AND black stems → Cassava Bacterial Blight'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 3,\n",
        "            'name': 'CBB_Rule_3',\n",
        "            'conditions': ['Leaf_wilting', 'Water_soaked_lesions'],\n",
        "            'conclusion': 'CBB',\n",
        "            'confidence': 0.75,\n",
        "            'description': 'If leaf wilting AND water-soaked lesions → Cassava Bacterial Blight'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 4,\n",
        "            'name': 'CBB_Treatment_Rule',\n",
        "            'conditions': ['CBB_diagnosed'],\n",
        "            'conclusion': 'Apply_copper_fungicides',\n",
        "            'confidence': 0.90,\n",
        "            'description': 'If CBB diagnosed → Apply copper-based fungicides'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 5,\n",
        "            'name': 'CBB_Severity_Rule',\n",
        "            'conditions': ['CBB_diagnosed', 'High_infection_rate'],\n",
        "            'conclusion': 'Remove_infected_plants',\n",
        "            'confidence': 0.95,\n",
        "            'description': 'If CBB AND high infection rate → Remove infected plants immediately'\n",
        "        })\n",
        "        \n",
        "        # Rule 6-10: CBSD (Cassava Brown Streak Disease) Rules\n",
        "        self.rules.append({\n",
        "            'id': 6,\n",
        "            'name': 'CBSD_Rule_1',\n",
        "            'conditions': ['Brown_streaks_on_stems', 'Yellowing_between_veins'],\n",
        "            'conclusion': 'CBSD',\n",
        "            'confidence': 0.88,\n",
        "            'description': 'If brown streaks on stems AND yellowing between veins → CBSD'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 7,\n",
        "            'name': 'CBSD_Rule_2',\n",
        "            'conditions': ['Root_necrosis', 'Chlorotic_mottling'],\n",
        "            'conclusion': 'CBSD',\n",
        "            'confidence': 0.85,\n",
        "            'description': 'If root necrosis AND chlorotic mottling → CBSD'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 8,\n",
        "            'name': 'CBSD_Rule_3',\n",
        "            'conditions': ['Stunted_growth', 'Brown_streaks_on_stems'],\n",
        "            'conclusion': 'CBSD',\n",
        "            'confidence': 0.82,\n",
        "            'description': 'If stunted growth AND brown streaks on stems → CBSD'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 9,\n",
        "            'name': 'CBSD_Treatment_Rule',\n",
        "            'conditions': ['CBSD_diagnosed'],\n",
        "            'conclusion': 'Use_virus_free_material',\n",
        "            'confidence': 0.92,\n",
        "            'description': 'If CBSD diagnosed → Use virus-free planting material'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 10,\n",
        "            'name': 'CBSD_Vector_Rule',\n",
        "            'conditions': ['CBSD_diagnosed', 'Whitefly_present'],\n",
        "            'conclusion': 'Control_whiteflies',\n",
        "            'confidence': 0.90,\n",
        "            'description': 'If CBSD AND whiteflies present → Control whitefly vectors'\n",
        "        })\n",
        "        \n",
        "        # Rule 11-15: CGM (Cassava Green Mottle) Rules\n",
        "        self.rules.append({\n",
        "            'id': 11,\n",
        "            'name': 'CGM_Rule_1',\n",
        "            'conditions': ['Green_mottling', 'Irregular_leaf_patterns'],\n",
        "            'conclusion': 'CGM',\n",
        "            'confidence': 0.80,\n",
        "            'description': 'If green mottling AND irregular leaf patterns → CGM'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 12,\n",
        "            'name': 'CGM_Rule_2',\n",
        "            'conditions': ['Distorted_leaves', 'Mild_yellowing'],\n",
        "            'conclusion': 'CGM',\n",
        "            'confidence': 0.75,\n",
        "            'description': 'If distorted leaves AND mild yellowing → CGM'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 13,\n",
        "            'name': 'CGM_Treatment_Rule',\n",
        "            'conditions': ['CGM_diagnosed'],\n",
        "            'conclusion': 'Remove_infected_plants',\n",
        "            'confidence': 0.85,\n",
        "            'description': 'If CGM diagnosed → Remove infected plants'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 14,\n",
        "            'name': 'CGM_Vector_Rule',\n",
        "            'conditions': ['CGM_diagnosed', 'Thrips_present'],\n",
        "            'conclusion': 'Control_thrips',\n",
        "            'confidence': 0.88,\n",
        "            'description': 'If CGM AND thrips present → Control thrips'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 15,\n",
        "            'name': 'CGM_Prevention_Rule',\n",
        "            'conditions': ['CGM_risk_high'],\n",
        "            'conclusion': 'Apply_preventive_spacing',\n",
        "            'confidence': 0.80,\n",
        "            'description': 'If CGM risk high → Ensure proper plant spacing'\n",
        "        })\n",
        "        \n",
        "        # Rule 16-20: CMD (Cassava Mosaic Disease) Rules\n",
        "        self.rules.append({\n",
        "            'id': 16,\n",
        "            'name': 'CMD_Rule_1',\n",
        "            'conditions': ['Mosaic_patterns', 'Leaf_distortion'],\n",
        "            'conclusion': 'CMD',\n",
        "            'confidence': 0.90,\n",
        "            'description': 'If mosaic patterns AND leaf distortion → CMD'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 17,\n",
        "            'name': 'CMD_Rule_2',\n",
        "            'conditions': ['Yellow_green_mottling', 'Severe_stunting'],\n",
        "            'conclusion': 'CMD',\n",
        "            'confidence': 0.87,\n",
        "            'description': 'If yellow-green mottling AND severe stunting → CMD'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 18,\n",
        "            'name': 'CMD_Rule_3',\n",
        "            'conditions': ['Reduced_leaf_size', 'Mosaic_patterns'],\n",
        "            'conclusion': 'CMD',\n",
        "            'confidence': 0.83,\n",
        "            'description': 'If reduced leaf size AND mosaic patterns → CMD'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 19,\n",
        "            'name': 'CMD_Treatment_Rule',\n",
        "            'conditions': ['CMD_diagnosed'],\n",
        "            'conclusion': 'Use_virus_free_cuttings',\n",
        "            'confidence': 0.93,\n",
        "            'description': 'If CMD diagnosed → Use virus-free cassava cuttings'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 20,\n",
        "            'name': 'CMD_Vector_Rule',\n",
        "            'conditions': ['CMD_diagnosed', 'Whitefly_present'],\n",
        "            'conclusion': 'Control_whitefly_populations',\n",
        "            'confidence': 0.91,\n",
        "            'description': 'If CMD AND whiteflies present → Control whitefly populations'\n",
        "        })\n",
        "        \n",
        "        # Additional rules (21-25) for treatment and prevention\n",
        "        self.rules.append({\n",
        "            'id': 21,\n",
        "            'name': 'General_Prevention_Rule_1',\n",
        "            'conditions': ['Early_season'],\n",
        "            'conclusion': 'Use_certified_planting_material',\n",
        "            'confidence': 0.85,\n",
        "            'description': 'If early season → Use certified planting material'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 22,\n",
        "            'name': 'General_Prevention_Rule_2',\n",
        "            'conditions': ['High_whitefly_population'],\n",
        "            'conclusion': 'Apply_preventive_insecticides',\n",
        "            'confidence': 0.88,\n",
        "            'description': 'If high whitefly population → Apply preventive insecticides'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 23,\n",
        "            'name': 'Severity_Escalation_Rule',\n",
        "            'conditions': ['Disease_diagnosed', 'Infection_rate_above_50'],\n",
        "            'conclusion': 'Immediate_field_management',\n",
        "            'confidence': 0.95,\n",
        "            'description': 'If disease diagnosed AND infection rate > 50% → Immediate field management required'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 24,\n",
        "            'name': 'Healthy_Maintenance_Rule',\n",
        "            'conditions': ['Uniform_green_color', 'No_lesions', 'Normal_growth'],\n",
        "            'conclusion': 'Healthy',\n",
        "            'confidence': 0.95,\n",
        "            'description': 'If uniform green, no lesions, normal growth → Healthy'\n",
        "        })\n",
        "        \n",
        "        self.rules.append({\n",
        "            'id': 25,\n",
        "            'name': 'Integrated_Management_Rule',\n",
        "            'conditions': ['Multiple_diseases_present'],\n",
        "            'conclusion': 'Apply_integrated_disease_management',\n",
        "            'confidence': 0.90,\n",
        "            'description': 'If multiple diseases present → Apply integrated disease management'\n",
        "        })\n",
        "    \n",
        "    def get_rules(self):\n",
        "        return self.rules\n",
        "    \n",
        "    def find_matching_rules(self, conditions):\n",
        "        \"\"\"Find rules that match given conditions\"\"\"\n",
        "        matching_rules = []\n",
        "        for rule in self.rules:\n",
        "            # Check if all rule conditions are met\n",
        "            if all(cond in conditions for cond in rule['conditions']):\n",
        "                matching_rules.append(rule)\n",
        "        return matching_rules\n",
        "    \n",
        "    def forward_chaining(self, initial_conditions):\n",
        "        \"\"\"Forward chaining inference engine\"\"\"\n",
        "        facts = set(initial_conditions)\n",
        "        conclusions = []\n",
        "        applied_rules = []\n",
        "        \n",
        "        changed = True\n",
        "        while changed:\n",
        "            changed = False\n",
        "            for rule in self.rules:\n",
        "                if rule['id'] not in applied_rules:\n",
        "                    # Check if all conditions are satisfied\n",
        "                    if all(cond in facts for cond in rule['conditions']):\n",
        "                        # Add conclusion to facts\n",
        "                        conclusion = rule['conclusion']\n",
        "                        facts.add(conclusion)\n",
        "                        conclusions.append({\n",
        "                            'rule': rule,\n",
        "                            'conclusion': conclusion,\n",
        "                            'confidence': rule['confidence']\n",
        "                        })\n",
        "                        applied_rules.append(rule['id'])\n",
        "                        changed = True\n",
        "        \n",
        "        return conclusions, facts\n",
        "\n",
        "# Initialize expert rules\n",
        "expert_rules = ExpertRules()\n",
        "rules = expert_rules.get_rules()\n",
        "\n",
        "print(f\"✓ Expert Rules Base initialized\")\n",
        "print(f\"  Total rules: {len(rules)}\")\n",
        "print(f\"\\nRule Summary:\")\n",
        "print(\"-\" * 70)\n",
        "for rule in rules[:10]:  # Show first 10 rules\n",
        "    print(f\"Rule {rule['id']}: {rule['description']}\")\n",
        "print(f\"... and {len(rules) - 10} more rules\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ontology to file\n",
        "ontology_file = \"agriculture_ontology.rdf\"\n",
        "kg.serialize(destination=ontology_file, format='xml')\n",
        "print(f\"✓ Ontology saved to: {ontology_file}\")\n",
        "\n",
        "# Save rules to JSON\n",
        "rules_file = \"expert_rules.json\"\n",
        "with open(rules_file, 'w') as f:\n",
        "    json.dump(rules, f, indent=2)\n",
        "print(f\"✓ Expert rules saved to: {rules_file}\")\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"KNOWLEDGE BASE SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Ontology Triples: {len(kg):,}\")\n",
        "print(f\"Expert Rules: {len(rules)}\")\n",
        "print(f\"Diseases: {len(diseases)}\")\n",
        "print(f\"Total Symptoms: {sum(len(s) for s in symptoms_db.values())}\")\n",
        "print(f\"Total Treatments: {sum(len(t) for t in treatments_db.values())}\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Reasoning Engine Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HybridReasoningEngine:\n",
        "    \"\"\"Hybrid reasoning engine combining KE and ML\"\"\"\n",
        "    \n",
        "    def __init__(self, expert_rules, disease_treatments):\n",
        "        self.expert_rules = expert_rules\n",
        "        self.disease_treatments = disease_treatments\n",
        "    \n",
        "    def reason_from_symptoms(self, observed_symptoms):\n",
        "        \"\"\"Reason about disease from observed symptoms\"\"\"\n",
        "        # Use forward chaining\n",
        "        conclusions, facts = self.expert_rules.forward_chaining(observed_symptoms)\n",
        "        \n",
        "        # Extract disease predictions\n",
        "        disease_predictions = {}\n",
        "        for conc in conclusions:\n",
        "            if conc['conclusion'] in ['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']:\n",
        "                disease_predictions[conc['conclusion']] = conc['confidence']\n",
        "        \n",
        "        return disease_predictions, conclusions\n",
        "    \n",
        "    def get_treatment_recommendations(self, disease):\n",
        "        \"\"\"Get treatment recommendations for a diagnosed disease\"\"\"\n",
        "        if disease in self.disease_treatments:\n",
        "            return self.disease_treatments[disease]\n",
        "        return []\n",
        "    \n",
        "    def hybrid_reasoning(self, ml_prediction, ml_confidence, observed_symptoms=None):\n",
        "        \"\"\"Combine ML prediction with KE reasoning\"\"\"\n",
        "        \n",
        "        # KE reasoning from symptoms (if provided)\n",
        "        ke_predictions = {}\n",
        "        if observed_symptoms:\n",
        "            ke_predictions, ke_conclusions = self.reason_from_symptoms(observed_symptoms)\n",
        "        \n",
        "        # Combine ML and KE predictions\n",
        "        final_prediction = ml_prediction\n",
        "        final_confidence = ml_confidence\n",
        "        \n",
        "        # If KE also predicts the same disease, boost confidence\n",
        "        if ml_prediction in ke_predictions:\n",
        "            ke_conf = ke_predictions[ml_prediction]\n",
        "            # Weighted combination: 70% ML, 30% KE\n",
        "            final_confidence = 0.7 * ml_confidence + 0.3 * ke_conf\n",
        "            reasoning_type = \"Hybrid (ML + KE agreement)\"\n",
        "        else:\n",
        "            # If disagreement, prefer ML but consider KE\n",
        "            if ke_predictions:\n",
        "                ke_pred = max(ke_predictions, key=ke_predictions.get)\n",
        "                if ke_predictions[ke_pred] > 0.8:  # Strong KE prediction\n",
        "                    # Moderate ML confidence if KE disagrees strongly\n",
        "                    final_confidence = ml_confidence * 0.9\n",
        "                    reasoning_type = f\"ML (KE suggests {ke_pred})\"\n",
        "                else:\n",
        "                    reasoning_type = \"ML (primary)\"\n",
        "            else:\n",
        "                reasoning_type = \"ML (no KE input)\"\n",
        "        \n",
        "        # Get treatments\n",
        "        treatments = self.get_treatment_recommendations(ml_prediction)\n",
        "        \n",
        "        return {\n",
        "            'disease': final_prediction,\n",
        "            'confidence': final_confidence,\n",
        "            'reasoning_type': reasoning_type,\n",
        "            'ml_prediction': ml_prediction,\n",
        "            'ml_confidence': ml_confidence,\n",
        "            'ke_predictions': ke_predictions,\n",
        "            'treatments': treatments\n",
        "        }\n",
        "\n",
        "# Initialize reasoning engine\n",
        "reasoning_engine = HybridReasoningEngine(expert_rules, treatments_db)\n",
        "print(\"✓ Hybrid Reasoning Engine initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for CNN training\n",
        "def prepare_dataset(base_path, img_size=(224, 224), test_split=0.2, val_split=0.2):\n",
        "    \"\"\"Prepare train/validation/test splits\"\"\"\n",
        "    \n",
        "    if not Path(base_path).exists():\n",
        "        print(f\"⚠ Path {base_path} does not exist\")\n",
        "        return None, None, None, None, None\n",
        "    \n",
        "    all_image_paths = []\n",
        "    all_labels = []\n",
        "    \n",
        "    folder_mapping = {\n",
        "        'Cassava___bacterial_blight': 0,\n",
        "        'Cassava___brown_streak_disease': 1,\n",
        "        'Cassava___green_mottle': 2,\n",
        "        'Cassava___mosaic_disease': 3,\n",
        "        'Cassava___healthy': 4\n",
        "    }\n",
        "    \n",
        "    # Collect all images\n",
        "    for folder_name, class_idx in folder_mapping.items():\n",
        "        folder_path = Path(base_path) / folder_name\n",
        "        if folder_path.exists():\n",
        "            for ext in ['.jpg', '.jpeg', '.png']:\n",
        "                images = list(folder_path.glob(f\"*{ext}\"))\n",
        "                for img_path in images:\n",
        "                    all_image_paths.append(str(img_path))\n",
        "                    all_labels.append(class_idx)\n",
        "    \n",
        "    all_image_paths = np.array(all_image_paths)\n",
        "    all_labels = np.array(all_labels)\n",
        "    \n",
        "    print(f\"Total images collected: {len(all_image_paths):,}\")\n",
        "    \n",
        "    # Split: train -> (1-test_split), test -> test_split\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        all_image_paths, all_labels, \n",
        "        test_size=test_split, \n",
        "        random_state=42, \n",
        "        stratify=all_labels\n",
        "    )\n",
        "    \n",
        "    # Further split train into train and validation\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "        train_paths, train_labels,\n",
        "        test_size=val_split,\n",
        "        random_state=42,\n",
        "        stratify=train_labels\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nData Split:\")\n",
        "    print(f\"  Training:   {len(train_paths):,} images ({len(train_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "    print(f\"  Validation: {len(val_paths):,} images ({len(val_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "    print(f\"  Test:       {len(test_paths):,} images ({len(test_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "    \n",
        "    return train_paths, val_paths, test_paths, train_labels, val_labels, test_labels\n",
        "\n",
        "# Prepare dataset\n",
        "if class_stats:\n",
        "    train_paths, val_paths, test_paths, train_labels, val_labels, test_labels = prepare_dataset(\n",
        "        BASE_DATA_PATH, img_size=(224, 224), test_split=0.2, val_split=0.2\n",
        "    )\n",
        "else:\n",
        "    print(\"⚠ Cannot prepare dataset - class_stats not available\")\n",
        "    train_paths = val_paths = test_paths = None\n",
        "    train_labels = val_labels = test_labels = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create TensorFlow datasets with data augmentation\n",
        "def load_and_preprocess_image(image_path, label, img_size=(224, 224), augment=False):\n",
        "    \"\"\"Load and preprocess image\"\"\"\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, img_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    \n",
        "    if augment:\n",
        "        # Data augmentation\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "        image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
        "        image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "def create_tf_dataset(image_paths, labels, img_size=(224, 224), batch_size=32, \n",
        "                     augment=False, shuffle=True, buffer_size=1000):\n",
        "    \"\"\"Create TensorFlow dataset\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "    \n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "    \n",
        "    dataset = dataset.map(\n",
        "        lambda x, y: load_and_preprocess_image(x, y, img_size, augment),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    \n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "# Create datasets\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "if train_paths is not None:\n",
        "    train_ds = create_tf_dataset(train_paths, train_labels, IMG_SIZE, BATCH_SIZE, \n",
        "                                augment=True, shuffle=True)\n",
        "    val_ds = create_tf_dataset(val_paths, val_labels, IMG_SIZE, BATCH_SIZE, \n",
        "                              augment=False, shuffle=False)\n",
        "    test_ds = create_tf_dataset(test_paths, test_labels, IMG_SIZE, BATCH_SIZE, \n",
        "                               augment=False, shuffle=False)\n",
        "    \n",
        "    print(\"✓ TensorFlow datasets created\")\n",
        "    print(f\"  Training batches: {len(train_ds)}\")\n",
        "    print(f\"  Validation batches: {len(val_ds)}\")\n",
        "    print(f\"  Test batches: {len(test_ds)}\")\n",
        "else:\n",
        "    train_ds = val_ds = test_ds = None\n",
        "    print(\"⚠ Cannot create datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 CNN Model Architecture - Baseline Model\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
